from fastapi import FastAPI, HTTPException
from pathlib import Path
from app.utils.time_series import load_energy_consumption_data ,save_data_to_influxdb
from app.services.prediction_service import apply_arima_model,save_predictions_to_postgres,get_influx_data,connect_postgresql
import pandas as pd
import numpy as np
from statsmodels.tsa.arima.model import ARIMA
from pydantic import BaseModel
import os

app = FastAPI()


# D√©finir le chemin du fichier de donn√©es
DATASET_DIR = Path("D:/PFE/DataSet")
FILE_CSV = DATASET_DIR / "Energy_consumption.csv"
data_cache = None  # Stocke les donn√©es apr√®s /load-data

@app.get("/")
def root():
    return {"message": "Bienvenue dans le service de pr√©diction"}


@app.get("/load-data")
def load_data():
    global data_cache  # Permet de modifier la variable globale

    try:
        print("üìÇ V√©rification de l'existence du fichier CSV...")
        if not os.path.exists(str(FILE_CSV)):  # V√©rifier si le fichier existe
            raise HTTPException(status_code=404, detail="Fichier introuvable. V√©rifiez le chemin.")

        # Charger les donn√©es
        df = load_energy_consumption_data(str(FILE_CSV))

        print("üîç V√©rification des premi√®res lignes du DataFrame...")
        print(df.head())

        # V√©rification des colonnes n√©cessaires
        if not all(col in df.columns for col in ['Year', 'Month', 'Day', 'Hour']):
            raise HTTPException(status_code=400, detail="Erreur : Les colonnes 'Year', 'Month', 'Day', 'Hour' sont manquantes.")

        # Reconstituer la colonne 'Timestamp'
        df['Timestamp'] = pd.to_datetime(df[['Year', 'Month', 'Day', 'Hour']], errors='coerce')

        if 'Timestamp' not in df.columns or df['Timestamp'].isnull().all():
            raise HTTPException(status_code=400, detail="Erreur : La colonne 'Timestamp' est absente ou contient des valeurs invalides.")

        # Enregistrer les donn√©es
        data_cache = df

        # Sauvegarder dans InfluxDB
        save_data_to_influxdb(df)

        # Retourner les donn√©es sous forme de dictionnaire
        data_dict = df[['Timestamp', 'Temperature', 'Humidity', 'SquareFootage', 'Occupancy', 'RenewableEnergy', 'EnergyConsumption']].head().to_dict(orient="records")
        return {"data": data_dict}

    except Exception as e:
        print(f"‚ùå Exception captur√©e : {e}")
        raise HTTPException(status_code=500, detail=f"Erreur lors du chargement des donn√©es : {e}")


@app.get("/forecast")
def forecast_data():
    """
    Route pour effectuer des pr√©visions sur les donn√©es de consommation d'√©nergie.
    """
    global data_cache  # On suppose que les donn√©es sont d√©j√† charg√©es dans `data_cache`

    if data_cache is None:
        raise HTTPException(status_code=400, detail="Les donn√©es doivent d'abord √™tre charg√©es via /load-data.")

    try:
        # Appliquer ARIMA sur les donn√©es charg√©es
        forecast_df = apply_arima_model(data_cache, steps=30)

        # Retourner les 10 derni√®res lignes (y compris les pr√©visions)
        return {"forecast": forecast_df.tail(10).to_dict(orient="records")}  # Utilisation de 'orient="records"' pour une r√©ponse lisible

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de la g√©n√©ration des pr√©visions : {e}")
    


class PredictionRequest(BaseModel):
    steps: int = 30

@app.post("/predict")
async def predict(request: PredictionRequest):
    """Endpoint pour r√©cup√©rer les donn√©es, faire une pr√©diction et enregistrer les r√©sultats."""
    
    # √âtape 1 : Charger les donn√©es depuis InfluxDB
    data = get_influx_data()
    
    print("Donn√©es r√©cup√©r√©es :", data)  # Ajout pour voir les donn√©es
    
    # V√©rification
    if "energyConsumption" not in data.columns:
        raise ValueError("Les donn√©es r√©cup√©r√©es ne contiennent pas 'energyConsumption'.")

    # √âtape 2 : Appliquer le mod√®le ARIMA pour pr√©dire
    forecast_df = apply_arima_model(data, steps=request.steps)

    # √âtape 3 : Enregistrer les pr√©visions dans PostgreSQL
    save_predictions_to_postgres(forecast_df)

    return {"message": "Les pr√©visions ont √©t√© g√©n√©r√©es et enregistr√©es avec succ√®s."}




@app.get("/predictions")
async def get_predictions():
    """Endpoint pour r√©cup√©rer les pr√©visions enregistr√©es dans PostgreSQL"""
    conn = connect_postgresql()
    cursor = conn.cursor()
    
    cursor.execute("SELECT timestamp, forecast FROM predictions ORDER BY timestamp DESC")
    data = cursor.fetchall()

    cursor.close()
    conn.close()

    if not data:
        return {"message": "Aucune pr√©vision disponible."}

    predictions = [{"timestamp": row[0], "forecast": row[1]} for row in data]
    return {"predictions": predictions}